{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41030b00-dab7-4c34-a4d0-dfcf7f6c9588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb1fb89-492d-480d-a88a-b645f8a92781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the necssary modules \n",
    "import folium \n",
    "from IPython.display import display, clear_output \n",
    "import numpy as np \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912a9877-cfb7-4faf-a7ac-cf96c4166004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MapEnv:\n",
    "    def __init__(self, startLat, startLng, goalLat, goalLng, stepSize=0.0005):\n",
    "        self.startLat = startLat\n",
    "        self.startLng = startLng\n",
    "        self.goalLat = goalLat\n",
    "        self.goalLng = goalLng\n",
    "        self.stepSize = stepSize\n",
    "        self.agentPath = []  # store all positions\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.lat = self.startLat\n",
    "        self.lng = self.startLng\n",
    "        self.done = False\n",
    "        self.agentPath = [(self.lat, self.lng)]\n",
    "        return (self.lat, self.lng)\n",
    "\n",
    "    def getDistanceToGoal(self):\n",
    "        return np.sqrt((self.lat - self.goalLat)**2 + (self.lng - self.goalLng)**2)\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            return (self.lat, self.lng), 0, self.done\n",
    "\n",
    "        # Actions: 0=N, 1=S, 2=E, 3=W\n",
    "        if action == 0:\n",
    "            self.lat += self.stepSize\n",
    "        elif action == 1:\n",
    "            self.lat -= self.stepSize\n",
    "        elif action == 2:\n",
    "            self.lng += self.stepSize\n",
    "        elif action == 3:\n",
    "            self.lng -= self.stepSize\n",
    "\n",
    "        self.agentPath.append((self.lat, self.lng))\n",
    "        distance = self.getDistanceToGoal()\n",
    "        reward = -distance\n",
    "        self.done = distance < 0.0003\n",
    "\n",
    "        return (self.lat, self.lng), reward, self.done\n",
    "\n",
    "    def render(self):\n",
    "        mapView = folium.Map(location=[self.lat, self.lng], zoom_start=18)\n",
    "\n",
    "        # Start & Goal markers\n",
    "        folium.Marker([self.startLat, self.startLng], popup='Start', icon=folium.Icon(color='blue')).add_to(mapView)\n",
    "        folium.Marker([self.goalLat, self.goalLng], popup='Goal', icon=folium.Icon(color='green')).add_to(mapView)\n",
    "\n",
    "        # Draw path\n",
    "        folium.PolyLine(self.agentPath, color='red', weight=5, opacity=0.8).add_to(mapView)\n",
    "\n",
    "        # Current position\n",
    "        folium.CircleMarker(location=[self.lat, self.lng], radius=6, color='red', fill=True).add_to(mapView)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(mapView)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c628a2a3-e1ea-448a-a9e1-35fad322034e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomAgentDemo():\n",
    "    # Start and goal coordinates\n",
    "    startLat, startLng = 6.5244, 3.3792\n",
    "    goalLat, goalLng = 6.5254, 3.3805\n",
    "\n",
    "    env = MapEnv(startLat, startLng, goalLat, goalLng)\n",
    "    state = env.reset()\n",
    "    env.render()\n",
    "\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = np.random.choice([0, 1, 2, 3])  # N, S, E, W\n",
    "        nextState, reward, done = env.step(action)\n",
    "        step += 1\n",
    "        print(f\"Step {step} | Action: {action} | State: {nextState} | Reward: {reward:.5f}\")\n",
    "        env.render()\n",
    "\n",
    "    print(\"Agent reached the goal!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2eaeb3-a0fc-4407-bc38-0185189140fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#randomAgentDemo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7194be6-6f08-483f-bfe9-7561283155cb",
   "metadata": {},
   "source": [
    "<h2> Second Part </h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7678a570-3a82-442d-888c-0bc290a49f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 19:41:10.231292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Q-Network Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, stateSize, actionSize):\n",
    "        self.stateSize = stateSize\n",
    "        self.actionSize = actionSize\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95     # discount rate\n",
    "        self.epsilon = 1.0    # exploration rate\n",
    "        self.epsilonMin = 0.01\n",
    "        self.epsilonDecay = 0.995\n",
    "        self.learningRate = 0.001\n",
    "        self.model = self._buildModel()\n",
    "\n",
    "    def _buildModel(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(64, input_dim=self.stateSize, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(120, activation='relu')) \n",
    "        model.add(tf.keras.layers.Dense(self.actionSize, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=self.learningRate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, nextState, done):\n",
    "        self.memory.append((state, action, reward, nextState, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.actionSize)\n",
    "        actValues = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(actValues[0])\n",
    "\n",
    "    def replay(self, batchSize=32):\n",
    "        minibatch = random.sample(self.memory, min(len(self.memory), batchSize))\n",
    "        for state, action, reward, nextState, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(self.model.predict(nextState, verbose=0)[0])\n",
    "            targetQ = self.model.predict(state, verbose=0)\n",
    "            targetQ[0][action] = target\n",
    "            self.model.fit(state, targetQ, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilonMin:\n",
    "            self.epsilon *= self.epsilonDecay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c3ce56-c1a2-40de-bc3a-3974924c2309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainDeepRlAgent(episodes=300):\n",
    "    startLat, startLng = 6.5244, 3.3792\n",
    "    goalLat, goalLng = 6.5254, 3.3805\n",
    "\n",
    "    env = MapEnv(startLat, startLng, goalLat, goalLng)\n",
    "    stateSize = 4  # [lat, lng, goal_lat, goal_lng]\n",
    "    actionSize = 4  # N, S, E, W\n",
    "\n",
    "    agent = DQNAgent(stateSize, actionSize)\n",
    "    scores = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        currentPosition = env.reset()\n",
    "        state = np.array([*currentPosition, goalLat, goalLng]).reshape(1, -1)\n",
    "        totalReward = 0\n",
    "        step = 0\n",
    "        done = False\n",
    "\n",
    "        while not done and step < 200:\n",
    "            action = agent.act(state)\n",
    "            nextPosition, reward, done = env.step(action)\n",
    "            nextState = np.array([*nextPosition, goalLat, goalLng]).reshape(1, -1)\n",
    "\n",
    "            agent.remember(state, action, reward, nextState, done)\n",
    "            state = nextState\n",
    "            totalReward += reward\n",
    "            step += 1\n",
    "\n",
    "        agent.replay()\n",
    "        scores.append(totalReward)\n",
    "\n",
    "        print(f\"Episode {episode+1}/{episodes}, Steps: {step}, TotalReward: {totalReward:.4f}, Epsilon: {agent.epsilon:.2f}\")\n",
    "\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f25a42-aa39-4683-ace6-712fedeed93f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testAgent(agent):\n",
    "    startLat, startLng = 6.5244, 3.3792\n",
    "    goalLat, goalLng = 6.5254, 3.3805\n",
    "\n",
    "    env = MapEnv(startLat, startLng, goalLat, goalLng)\n",
    "    state = np.array([*env.reset(), goalLat, goalLng]).reshape(1, -1)\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    while not done and steps < 200:\n",
    "        action = agent.act(state)\n",
    "        nextStateCoord, reward, done = env.step(action)\n",
    "        state = np.array([*nextStateCoord, goalLat, goalLng]).reshape(1, -1)\n",
    "        steps += 1\n",
    "        print(f\"Step {steps}: Action={action}, Reward={reward:.3f}\")\n",
    "        env.render()\n",
    "\n",
    "    print(\"Agent reached the goal!\" if done else \"Agent failed to reach the goal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d3d4ab0-cf62-44c0-a0f7-759ff2bee407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_695b942daee4153cf323a9f9881406ad {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_695b942daee4153cf323a9f9881406ad&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_695b942daee4153cf323a9f9881406ad = L.map(\n",
       "                &quot;map_695b942daee4153cf323a9f9881406ad&quot;,\n",
       "                {\n",
       "                    center: [6.522900000000001, 3.4077000000000095],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 18,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_a0be860116bdc17cc98d573045a6ead9 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_a0be860116bdc17cc98d573045a6ead9.addTo(map_695b942daee4153cf323a9f9881406ad);\n",
       "        \n",
       "    \n",
       "            var marker_cbf15fc1a13eccfc353270b64b704ba8 = L.marker(\n",
       "                [6.5244, 3.3792],\n",
       "                {}\n",
       "            ).addTo(map_695b942daee4153cf323a9f9881406ad);\n",
       "        \n",
       "    \n",
       "            var icon_bce94a78e3b20c5d8fea809541d88f88 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_cbf15fc1a13eccfc353270b64b704ba8.setIcon(icon_bce94a78e3b20c5d8fea809541d88f88);\n",
       "        \n",
       "    \n",
       "        var popup_c0b9ddaa2ed216c017dc05faf22a1c30 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_66c58b5facb8bce7da16adb18dbe54b6 = $(`&lt;div id=&quot;html_66c58b5facb8bce7da16adb18dbe54b6&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Start&lt;/div&gt;`)[0];\n",
       "                popup_c0b9ddaa2ed216c017dc05faf22a1c30.setContent(html_66c58b5facb8bce7da16adb18dbe54b6);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_cbf15fc1a13eccfc353270b64b704ba8.bindPopup(popup_c0b9ddaa2ed216c017dc05faf22a1c30)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d2c32cf88315c3dada8bb8212447060f = L.marker(\n",
       "                [6.5254, 3.3805],\n",
       "                {}\n",
       "            ).addTo(map_695b942daee4153cf323a9f9881406ad);\n",
       "        \n",
       "    \n",
       "            var icon_f3d07ddfcf673eec4699990ee6502ac3 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;green&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_d2c32cf88315c3dada8bb8212447060f.setIcon(icon_f3d07ddfcf673eec4699990ee6502ac3);\n",
       "        \n",
       "    \n",
       "        var popup_88972fd82a74d8704ad1f4c5fe3f7e48 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_86094a5786c49a28ddc19c0cb6a584ec = $(`&lt;div id=&quot;html_86094a5786c49a28ddc19c0cb6a584ec&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Goal&lt;/div&gt;`)[0];\n",
       "                popup_88972fd82a74d8704ad1f4c5fe3f7e48.setContent(html_86094a5786c49a28ddc19c0cb6a584ec);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d2c32cf88315c3dada8bb8212447060f.bindPopup(popup_88972fd82a74d8704ad1f4c5fe3f7e48)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var poly_line_4fa16227dd7d8c6ac3373324a1e772ff = L.polyline(\n",
       "                [[6.5244, 3.3792], [6.5244, 3.3787], [6.5239, 3.3787], [6.5234000000000005, 3.3787], [6.5234000000000005, 3.3792], [6.5234000000000005, 3.3797], [6.522900000000001, 3.3797], [6.522400000000001, 3.3797], [6.522400000000001, 3.3802000000000003], [6.522400000000001, 3.3807000000000005], [6.521900000000001, 3.3807000000000005], [6.522400000000001, 3.3807000000000005], [6.521900000000001, 3.3807000000000005], [6.521900000000001, 3.3812000000000006], [6.521400000000002, 3.3812000000000006], [6.521400000000002, 3.381700000000001], [6.521900000000001, 3.381700000000001], [6.521900000000001, 3.3812000000000006], [6.521400000000002, 3.3812000000000006], [6.520900000000002, 3.3812000000000006], [6.520900000000002, 3.381700000000001], [6.520900000000002, 3.382200000000001], [6.520900000000002, 3.382700000000001], [6.520400000000002, 3.382700000000001], [6.5199000000000025, 3.382700000000001], [6.5199000000000025, 3.3832000000000013], [6.5199000000000025, 3.3837000000000015], [6.519400000000003, 3.3837000000000015], [6.519400000000003, 3.3832000000000013], [6.5199000000000025, 3.3832000000000013], [6.5199000000000025, 3.382700000000001], [6.5199000000000025, 3.382200000000001], [6.5199000000000025, 3.382700000000001], [6.519400000000003, 3.382700000000001], [6.5199000000000025, 3.382700000000001], [6.5199000000000025, 3.382200000000001], [6.5199000000000025, 3.381700000000001], [6.520400000000002, 3.381700000000001], [6.520400000000002, 3.382200000000001], [6.520900000000002, 3.382200000000001], [6.520900000000002, 3.381700000000001], [6.521400000000002, 3.381700000000001], [6.521400000000002, 3.382200000000001], [6.520900000000002, 3.382200000000001], [6.520900000000002, 3.382700000000001], [6.520900000000002, 3.3832000000000013], [6.520900000000002, 3.3837000000000015], [6.520900000000002, 3.3832000000000013], [6.520900000000002, 3.3837000000000015], [6.521400000000002, 3.3837000000000015], [6.521400000000002, 3.3842000000000017], [6.521400000000002, 3.384700000000002], [6.521400000000002, 3.385200000000002], [6.521400000000002, 3.384700000000002], [6.521400000000002, 3.3842000000000017], [6.521400000000002, 3.384700000000002], [6.521900000000001, 3.384700000000002], [6.521900000000001, 3.385200000000002], [6.521900000000001, 3.385700000000002], [6.521400000000002, 3.385700000000002], [6.521400000000002, 3.3862000000000023], [6.520900000000002, 3.3862000000000023], [6.520900000000002, 3.385700000000002], [6.521400000000002, 3.385700000000002], [6.521400000000002, 3.3862000000000023], [6.520900000000002, 3.3862000000000023], [6.520400000000002, 3.3862000000000023], [6.520400000000002, 3.3867000000000025], [6.520900000000002, 3.3867000000000025], [6.520900000000002, 3.3872000000000027], [6.520900000000002, 3.387700000000003], [6.520900000000002, 3.388200000000003], [6.520900000000002, 3.388700000000003], [6.521400000000002, 3.388700000000003], [6.521400000000002, 3.3892000000000033], [6.521400000000002, 3.3897000000000035], [6.521400000000002, 3.3902000000000037], [6.521400000000002, 3.390700000000004], [6.521400000000002, 3.391200000000004], [6.521400000000002, 3.391700000000004], [6.521900000000001, 3.391700000000004], [6.521900000000001, 3.3922000000000043], [6.521900000000001, 3.3927000000000045], [6.521900000000001, 3.3922000000000043], [6.521900000000001, 3.3927000000000045], [6.522400000000001, 3.3927000000000045], [6.522900000000001, 3.3927000000000045], [6.522900000000001, 3.3932000000000047], [6.522900000000001, 3.393700000000005], [6.522900000000001, 3.3932000000000047], [6.522900000000001, 3.393700000000005], [6.522900000000001, 3.394200000000005], [6.522900000000001, 3.393700000000005], [6.522900000000001, 3.394200000000005], [6.522900000000001, 3.394700000000005], [6.522900000000001, 3.394200000000005], [6.522900000000001, 3.394700000000005], [6.5234000000000005, 3.394700000000005], [6.522900000000001, 3.394700000000005], [6.522400000000001, 3.394700000000005], [6.522400000000001, 3.394200000000005], [6.522400000000001, 3.394700000000005], [6.522900000000001, 3.394700000000005], [6.522900000000001, 3.3952000000000053], [6.5234000000000005, 3.3952000000000053], [6.5239, 3.3952000000000053], [6.5239, 3.3957000000000055], [6.5239, 3.3962000000000057], [6.5234000000000005, 3.3962000000000057], [6.5234000000000005, 3.396700000000006], [6.522900000000001, 3.396700000000006], [6.522400000000001, 3.396700000000006], [6.522400000000001, 3.397200000000006], [6.522400000000001, 3.397700000000006], [6.522400000000001, 3.397200000000006], [6.522900000000001, 3.397200000000006], [6.522900000000001, 3.396700000000006], [6.522900000000001, 3.3962000000000057], [6.522900000000001, 3.396700000000006], [6.522900000000001, 3.397200000000006], [6.522900000000001, 3.397700000000006], [6.5234000000000005, 3.397700000000006], [6.5234000000000005, 3.397200000000006], [6.522900000000001, 3.397200000000006], [6.522900000000001, 3.397700000000006], [6.522900000000001, 3.3982000000000063], [6.522400000000001, 3.3982000000000063], [6.522400000000001, 3.397700000000006], [6.522400000000001, 3.3982000000000063], [6.522400000000001, 3.3987000000000065], [6.522900000000001, 3.3987000000000065], [6.522900000000001, 3.3992000000000067], [6.522900000000001, 3.3987000000000065], [6.522900000000001, 3.3982000000000063], [6.522900000000001, 3.397700000000006], [6.522900000000001, 3.397200000000006], [6.522400000000001, 3.397200000000006], [6.522400000000001, 3.397700000000006], [6.521900000000001, 3.397700000000006], [6.521900000000001, 3.3982000000000063], [6.522400000000001, 3.3982000000000063], [6.522900000000001, 3.3982000000000063], [6.522900000000001, 3.3987000000000065], [6.522900000000001, 3.3992000000000067], [6.522400000000001, 3.3992000000000067], [6.521900000000001, 3.3992000000000067], [6.521900000000001, 3.3987000000000065], [6.521900000000001, 3.3992000000000067], [6.522400000000001, 3.3992000000000067], [6.521900000000001, 3.3992000000000067], [6.522400000000001, 3.3992000000000067], [6.522900000000001, 3.3992000000000067], [6.522900000000001, 3.3987000000000065], [6.522400000000001, 3.3987000000000065], [6.522400000000001, 3.3992000000000067], [6.522400000000001, 3.399700000000007], [6.522400000000001, 3.3992000000000067], [6.522400000000001, 3.399700000000007], [6.522400000000001, 3.400200000000007], [6.522400000000001, 3.399700000000007], [6.522400000000001, 3.400200000000007], [6.522400000000001, 3.400700000000007], [6.522900000000001, 3.400700000000007], [6.5234000000000005, 3.400700000000007], [6.5234000000000005, 3.400200000000007], [6.5234000000000005, 3.400700000000007], [6.5239, 3.400700000000007], [6.5239, 3.4012000000000073], [6.5244, 3.4012000000000073], [6.5244, 3.400700000000007], [6.5239, 3.400700000000007], [6.5244, 3.400700000000007], [6.5244, 3.4012000000000073], [6.5239, 3.4012000000000073], [6.5239, 3.4017000000000075], [6.5239, 3.4022000000000077], [6.5239, 3.402700000000008], [6.5244, 3.402700000000008], [6.5244, 3.4022000000000077], [6.5244, 3.402700000000008], [6.5244, 3.403200000000008], [6.5239, 3.403200000000008], [6.5239, 3.402700000000008], [6.5239, 3.403200000000008], [6.5239, 3.403700000000008], [6.5239, 3.4042000000000083], [6.5239, 3.4047000000000085], [6.5239, 3.4052000000000087], [6.5234000000000005, 3.4052000000000087], [6.522900000000001, 3.4052000000000087], [6.522900000000001, 3.405700000000009], [6.522900000000001, 3.406200000000009], [6.5234000000000005, 3.406200000000009], [6.5234000000000005, 3.406700000000009], [6.522900000000001, 3.406700000000009], [6.5234000000000005, 3.406700000000009], [6.522900000000001, 3.406700000000009], [6.522900000000001, 3.4072000000000093], [6.522900000000001, 3.4077000000000095], [6.522900000000001, 3.4072000000000093], [6.522900000000001, 3.4077000000000095]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 0.8, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 5}\n",
       "            ).addTo(map_695b942daee4153cf323a9f9881406ad);\n",
       "        \n",
       "    \n",
       "            var circle_marker_a689021b844f7817dec6d5c7d026a502 = L.circleMarker(\n",
       "                [6.522900000000001, 3.4077000000000095],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 6, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_695b942daee4153cf323a9f9881406ad);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x77e4c6150250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent failed to reach the goal.\n"
     ]
    }
   ],
   "source": [
    "trainedAgent = trainDeepRlAgent(episodes=50)\n",
    "testAgent(trainedAgent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "281335ce-565d-45df-a16b-afe592a8bfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainedAgent.model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e347936-893e-4da9-96c8-d569bde1ff6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2164001c-a6e4-47ed-af4c-c3dbf2171ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Environment Class\n",
    "class MapEnv:\n",
    "    def __init__(self, startLat, startLng, goalLat, goalLng, stepSize=0.0001):\n",
    "        self.startLat = startLat\n",
    "        self.startLng = startLng\n",
    "        self.goalLat = goalLat\n",
    "        self.goalLng = goalLng\n",
    "        self.stepSize = stepSize\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.agentLat = self.startLat\n",
    "        self.agentLng = self.startLng\n",
    "        return self._getState()\n",
    "\n",
    "    def _getState(self):\n",
    "        # Normalize to center around 0\n",
    "        return np.array([\n",
    "            self.agentLat - self.goalLat,\n",
    "            self.agentLng - self.goalLng\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        # 0=N, 1=S, 2=E, 3=W\n",
    "        if action == 0: self.agentLat += self.stepSize\n",
    "        elif action == 1: self.agentLat -= self.stepSize\n",
    "        elif action == 2: self.agentLng += self.stepSize\n",
    "        elif action == 3: self.agentLng -= self.stepSize\n",
    "\n",
    "        nextState = self._getState()\n",
    "        dist = np.linalg.norm(nextState)\n",
    "        done = dist < 0.0002\n",
    "        reward = 10.0 if done else -dist * 10  # Reward closer steps\n",
    "\n",
    "        return nextState, reward, done\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Agent at: ({self.agentLat:.6f}, {self.agentLng:.6f})\")\n",
    "\n",
    "# DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, stateSize, actionSize):\n",
    "        self.stateSize = stateSize\n",
    "        self.actionSize = actionSize\n",
    "        self.memory = []\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilonMin = 0.01\n",
    "        self.epsilonDecay = 0.995\n",
    "        self.learningRate = 0.001\n",
    "        self.model = self._buildModel()\n",
    "\n",
    "    def _buildModel(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=self.stateSize, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(self.actionSize, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learningRate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, nextState, done):\n",
    "        self.memory.append((state, action, reward, nextState, done))\n",
    "        if len(self.memory) > 2000:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.actionSize)\n",
    "        qValues = self.model.predict(state[np.newaxis, :], verbose=0)\n",
    "        return np.argmax(qValues[0])\n",
    "\n",
    "    def replay(self, batchSize=32):\n",
    "        if len(self.memory) < batchSize:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batchSize)\n",
    "        for state, action, reward, nextState, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(self.model.predict(nextState[np.newaxis, :], verbose=0)[0])\n",
    "            targetF = self.model.predict(state[np.newaxis, :], verbose=0)\n",
    "            targetF[0][action] = target\n",
    "            self.model.fit(state[np.newaxis, :], targetF, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilonMin:\n",
    "            self.epsilon *= self.epsilonDecay\n",
    "\n",
    "# Train function\n",
    "def trainAgent(episodes=300):\n",
    "    startLat, startLng = 6.5244, 3.3792\n",
    "    goalLat, goalLng = 6.5254, 3.3805\n",
    "    env = MapEnv(startLat, startLng, goalLat, goalLng)\n",
    "    agent = DQNAgent(stateSize=2, actionSize=4)\n",
    "\n",
    "    for e in range(episodes):\n",
    "        state = env.reset()\n",
    "        totalReward = 0\n",
    "        done = False\n",
    "        step = 0\n",
    "\n",
    "        while not done and step < 100:\n",
    "            action = agent.act(state)\n",
    "            nextState, reward, done = env.step(action)\n",
    "            agent.remember(state, action, reward, nextState, done)\n",
    "            state = nextState\n",
    "            totalReward += reward\n",
    "            step += 1\n",
    "\n",
    "        agent.replay()\n",
    "        print(f\"Episode {e+1}: Reward={totalReward:.2f} Epsilon={agent.epsilon:.2f}\")\n",
    "\n",
    "    agent.model.save(\"geoNavigationModel.h5\")\n",
    "    return agent\n",
    "\n",
    "# Test function\n",
    "def testAgent(agent):\n",
    "    env = MapEnv(6.5244, 3.3792, 6.5254, 3.3805)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    print(\"Starting Test...\")\n",
    "\n",
    "    while not done and step < 100:\n",
    "        action = agent.act(state)\n",
    "        nextState, reward, done = env.step(action)\n",
    "        state = nextState\n",
    "        env.render()\n",
    "        step += 1\n",
    "\n",
    "    print(\"✅ Goal reached!\" if done else \"❌ Failed to reach goal.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13ed9f6-a9c6-44e0-87e9-211646699a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward=-2.68 Epsilon=0.99\n",
      "Episode 2: Reward=-1.10 Epsilon=0.99\n",
      "Episode 3: Reward=-1.80 Epsilon=0.99\n",
      "Episode 4: Reward=-1.60 Epsilon=0.98\n",
      "Episode 5: Reward=-1.30 Epsilon=0.98\n",
      "Episode 6: Reward=-1.06 Epsilon=0.97\n",
      "Episode 7: Reward=-1.99 Epsilon=0.97\n",
      "Episode 8: Reward=-2.77 Epsilon=0.96\n",
      "Episode 9: Reward=-1.27 Epsilon=0.96\n",
      "Episode 10: Reward=-1.86 Epsilon=0.95\n",
      "Episode 11: Reward=-1.00 Epsilon=0.95\n",
      "Episode 12: Reward=-1.37 Epsilon=0.94\n",
      "Episode 13: Reward=-1.35 Epsilon=0.94\n",
      "Episode 14: Reward=-1.19 Epsilon=0.93\n",
      "Episode 15: Reward=-2.19 Epsilon=0.93\n",
      "Episode 16: Reward=-1.21 Epsilon=0.92\n",
      "Episode 17: Reward=-1.43 Epsilon=0.92\n",
      "Episode 18: Reward=-1.57 Epsilon=0.91\n",
      "Episode 19: Reward=-1.66 Epsilon=0.91\n",
      "Episode 20: Reward=-1.02 Epsilon=0.90\n",
      "Episode 21: Reward=-2.53 Epsilon=0.90\n",
      "Episode 22: Reward=-1.77 Epsilon=0.90\n",
      "Episode 23: Reward=-1.74 Epsilon=0.89\n",
      "Episode 24: Reward=-2.81 Epsilon=0.89\n",
      "Episode 25: Reward=-1.44 Epsilon=0.88\n",
      "Episode 26: Reward=-1.04 Epsilon=0.88\n",
      "Episode 27: Reward=-2.06 Epsilon=0.87\n",
      "Episode 28: Reward=-1.74 Epsilon=0.87\n",
      "Episode 29: Reward=-1.97 Epsilon=0.86\n",
      "Episode 30: Reward=-2.46 Epsilon=0.86\n",
      "Episode 31: Reward=-1.55 Epsilon=0.86\n",
      "Episode 32: Reward=-1.79 Epsilon=0.85\n",
      "Episode 33: Reward=-1.53 Epsilon=0.85\n",
      "Episode 34: Reward=-1.65 Epsilon=0.84\n",
      "Episode 35: Reward=-1.27 Epsilon=0.84\n",
      "Episode 36: Reward=-1.30 Epsilon=0.83\n",
      "Episode 37: Reward=-2.68 Epsilon=0.83\n",
      "Episode 38: Reward=-1.05 Epsilon=0.83\n",
      "Episode 39: Reward=-2.51 Epsilon=0.82\n",
      "Episode 40: Reward=-0.98 Epsilon=0.82\n",
      "Episode 41: Reward=-1.38 Epsilon=0.81\n",
      "Episode 42: Reward=-3.10 Epsilon=0.81\n",
      "Episode 43: Reward=-1.38 Epsilon=0.81\n",
      "Episode 44: Reward=-2.27 Epsilon=0.80\n",
      "Episode 45: Reward=-2.54 Epsilon=0.80\n",
      "Episode 46: Reward=-1.39 Epsilon=0.79\n",
      "Episode 47: Reward=-1.74 Epsilon=0.79\n",
      "Episode 48: Reward=-2.03 Epsilon=0.79\n",
      "Episode 49: Reward=-1.92 Epsilon=0.78\n",
      "Episode 50: Reward=-1.63 Epsilon=0.78\n",
      "Starting Test...\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524600, 3.379200)\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524600, 3.379100)\n",
      "Agent at: (6.524700, 3.379100)\n",
      "Agent at: (6.524700, 3.379000)\n",
      "Agent at: (6.524800, 3.379000)\n",
      "Agent at: (6.524800, 3.378900)\n",
      "Agent at: (6.524700, 3.378900)\n",
      "Agent at: (6.524700, 3.378800)\n",
      "Agent at: (6.524700, 3.378700)\n",
      "Agent at: (6.524700, 3.378800)\n",
      "Agent at: (6.524700, 3.378700)\n",
      "Agent at: (6.524600, 3.378700)\n",
      "Agent at: (6.524500, 3.378700)\n",
      "Agent at: (6.524400, 3.378700)\n",
      "Agent at: (6.524500, 3.378700)\n",
      "Agent at: (6.524500, 3.378800)\n",
      "Agent at: (6.524400, 3.378800)\n",
      "Agent at: (6.524400, 3.378900)\n",
      "Agent at: (6.524500, 3.378900)\n",
      "Agent at: (6.524500, 3.379000)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524400, 3.379100)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524400, 3.379100)\n",
      "Agent at: (6.524300, 3.379100)\n",
      "Agent at: (6.524300, 3.379000)\n",
      "Agent at: (6.524400, 3.379000)\n",
      "Agent at: (6.524400, 3.379100)\n",
      "Agent at: (6.524400, 3.379000)\n",
      "Agent at: (6.524500, 3.379000)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524400, 3.379100)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524500, 3.379000)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524400, 3.379200)\n",
      "Agent at: (6.524300, 3.379200)\n",
      "Agent at: (6.524300, 3.379300)\n",
      "Agent at: (6.524200, 3.379300)\n",
      "Agent at: (6.524200, 3.379400)\n",
      "Agent at: (6.524200, 3.379300)\n",
      "Agent at: (6.524100, 3.379300)\n",
      "Agent at: (6.524200, 3.379300)\n",
      "Agent at: (6.524300, 3.379300)\n",
      "Agent at: (6.524300, 3.379200)\n",
      "Agent at: (6.524300, 3.379300)\n",
      "Agent at: (6.524300, 3.379400)\n",
      "Agent at: (6.524200, 3.379400)\n",
      "Agent at: (6.524100, 3.379400)\n",
      "Agent at: (6.524100, 3.379300)\n",
      "Agent at: (6.524000, 3.379300)\n",
      "Agent at: (6.524000, 3.379400)\n",
      "Agent at: (6.524100, 3.379400)\n",
      "Agent at: (6.524200, 3.379400)\n",
      "Agent at: (6.524300, 3.379400)\n",
      "Agent at: (6.524200, 3.379400)\n",
      "Agent at: (6.524100, 3.379400)\n",
      "Agent at: (6.524000, 3.379400)\n",
      "Agent at: (6.524100, 3.379400)\n",
      "Agent at: (6.524200, 3.379400)\n",
      "Agent at: (6.524300, 3.379400)\n",
      "Agent at: (6.524400, 3.379400)\n",
      "Agent at: (6.524500, 3.379400)\n",
      "Agent at: (6.524600, 3.379400)\n",
      "Agent at: (6.524600, 3.379300)\n",
      "Agent at: (6.524600, 3.379400)\n",
      "Agent at: (6.524700, 3.379400)\n",
      "Agent at: (6.524800, 3.379400)\n",
      "Agent at: (6.524800, 3.379300)\n",
      "Agent at: (6.524900, 3.379300)\n",
      "Agent at: (6.524800, 3.379300)\n",
      "Agent at: (6.524700, 3.379300)\n",
      "Agent at: (6.524700, 3.379400)\n",
      "Agent at: (6.524600, 3.379400)\n",
      "Agent at: (6.524600, 3.379300)\n",
      "Agent at: (6.524500, 3.379300)\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524600, 3.379200)\n",
      "Agent at: (6.524700, 3.379200)\n",
      "Agent at: (6.524600, 3.379200)\n",
      "Agent at: (6.524600, 3.379100)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524600, 3.379200)\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524500, 3.379100)\n",
      "Agent at: (6.524500, 3.379200)\n",
      "Agent at: (6.524600, 3.379200)\n",
      "Agent at: (6.524700, 3.379200)\n",
      "Agent at: (6.524700, 3.379300)\n",
      "Agent at: (6.524700, 3.379200)\n",
      "Agent at: (6.524600, 3.379200)\n",
      "Agent at: (6.524600, 3.379300)\n",
      "Agent at: (6.524500, 3.379300)\n",
      "Agent at: (6.524600, 3.379300)\n",
      "Agent at: (6.524700, 3.379300)\n",
      "❌ Failed to reach goal.\n"
     ]
    }
   ],
   "source": [
    "# --- RUN THE AGENT ---\n",
    "# trainedAgent = trainAgent(episodes=300)\n",
    "trainedAgent = trainAgent(episodes=50) \n",
    "testAgent(trainedAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5f9c6-f439-4900-a432-54caf35b8a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
